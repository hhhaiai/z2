# Z2 - Z.ai OpenAIå…¼å®¹APIä»£ç†

è¿™æ˜¯ä¸€ä¸ªä¸ºZ.ai GLM-4.5æ¨¡å‹æä¾›OpenAIå…¼å®¹APIæ¥å£çš„é«˜æ€§èƒ½ä»£ç†æœåŠ¡å™¨ã€‚æ”¯æŒæµå¼å’Œéæµå¼å“åº”ï¼Œå…·å¤‡å®Œæ•´çš„ç»Ÿè®¡ç›‘æ§åŠŸèƒ½ï¼Œæ— éœ€é…ç½®å³å¯è¿è¡Œã€‚

## âœ¨ ä¸»è¦åŠŸèƒ½

- ğŸ”„ **OpenAI APIå…¼å®¹**: å®Œå…¨å…¼å®¹OpenAIçš„APIæ ¼å¼ï¼Œæ— éœ€ä¿®æ”¹å®¢æˆ·ç«¯ä»£ç 
- ğŸŒŠ **æµå¼å“åº”æ”¯æŒ**: æ”¯æŒå®æ—¶æµå¼è¾“å‡ºï¼Œæä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ
- ğŸ“Š **å®æ—¶ç»Ÿè®¡**: å†…ç½®Webç»Ÿè®¡é¢æ¿ï¼Œå®æ—¶ç›‘æ§APIä½¿ç”¨æƒ…å†µ
- ğŸ” **åŒ¿åè®¿é—®**: æ— éœ€APIå¯†é’¥å³å¯ä½¿ç”¨ï¼Œè‡ªåŠ¨è·å–åŒ¿åtoken
- ğŸš€ **é›¶é…ç½®å¯åŠ¨**: æ— éœ€ä»»ä½•ç¯å¢ƒå˜é‡å³å¯è¿è¡Œ
- ğŸ³ **Dockeræ”¯æŒ**: æä¾›Dockeré•œåƒï¼Œä¾¿äºéƒ¨ç½²

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æœ¬åœ°éƒ¨ç½²

1. **å…‹éš†ä»“åº“**
   ```bash
   git clone https://github.com/your-username/z2.git
   cd z2
   ```

2. **ç›´æ¥è¿è¡Œ**
   ```bash
   go run main.go
   ```
   
   æˆ–è€…ç¼–è¯‘åè¿è¡Œï¼š
   ```bash
   go build -o main main.go
   ./main
   ```

3. **éªŒè¯æœåŠ¡**
   ```bash
   # æ£€æŸ¥æ¨¡å‹åˆ—è¡¨
   curl http://localhost:7860/v1/models
   
   # æµ‹è¯•èŠå¤©æ¥å£
   curl -X POST http://localhost:7860/v1/chat/completions \
     -H "Content-Type: application/json" \
     -d '{"model": "GLM-4.5", "messages": [{"role": "user", "content": "ä½ å¥½"}]}'
   ```

4. **è®¿é—®ç»Ÿè®¡é¢æ¿**
   ```
   http://localhost:7860/stats
   ```

### Dockeréƒ¨ç½²

**æœ¬åœ°æ„å»ºï¼š**
```bash
# æ„å»ºå¹¶è¿è¡Œ
docker build -t z2-api .
docker run -p 7860:7860 z2-api
```

**ä½¿ç”¨é¢„æ„å»ºé•œåƒï¼š**
```bash
# ä½¿ç”¨GitHub Container Registryçš„é•œåƒ
docker run -p 7860:7860 ghcr.io/your-username/z2:latest
```

**GitHub Actionsè‡ªåŠ¨æ„å»ºï¼š**
- æ¨é€tagæ—¶è‡ªåŠ¨æ„å»ºå¤šæ¶æ„Dockeré•œåƒï¼ˆamd64ã€arm64ã€armv7ï¼‰
- é•œåƒå‘å¸ƒåˆ°GitHub Container Registry
- æ”¯æŒç‰ˆæœ¬æ ‡ç­¾å’Œlatestæ ‡ç­¾

## ğŸ“– ä½¿ç”¨æ–¹æ³•

### Pythonç¤ºä¾‹

```python
import openai

# é…ç½®å®¢æˆ·ç«¯ï¼ˆæ— éœ€APIå¯†é’¥ï¼‰
client = openai.OpenAI(
    api_key="sk-any-key",  # å¯ä»¥æ˜¯ä»»æ„å€¼
    base_url="http://localhost:7860/v1"
)

# éæµå¼è¯·æ±‚
response = client.chat.completions.create(
    model="GLM-4.5",
    messages=[{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"}]
)
print(response.choices[0].message.content)

# æµå¼è¯·æ±‚
response = client.chat.completions.create(
    model="GLM-4.5",
    messages=[{"role": "user", "content": "è¯·å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—"}],
    stream=True
)
for chunk in response:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

### curlç¤ºä¾‹

```bash
# è·å–æ¨¡å‹åˆ—è¡¨
curl http://localhost:7860/v1/models

# éæµå¼èŠå¤©
curl -X POST http://localhost:7860/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "GLM-4.5",
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "stream": false
  }'

curl -X POST http://localhost:7860/api/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "GLM-4.5",
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "stream": false
  }'

# æµå¼èŠå¤©
curl -X POST http://localhost:7860/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "GLM-4.5",
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "stream": true
  }'

curl -X POST http://localhost:7860/api/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "GLM-4.5",
    "messages": [{"role": "user", "content": "ä½ å¥½"}],
    "stream": true
  }'

```

### JavaScriptç¤ºä¾‹

```javascript
async function chatWithGLM(message) {
  const response = await fetch('http://localhost:7860/v1/chat/completions', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: 'GLM-4.5',
      messages: [{ role: 'user', content: message }]
    })
  });
  
  const data = await response.json();
  console.log(data.choices[0].message.content);
}

chatWithGLM('ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹JavaScript');
```